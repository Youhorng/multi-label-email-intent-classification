{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Multi-label Email Classification Fine-Tuning Task on BERT Variants**\n",
    "\n",
    "**Objective:** The goal of this task is to address the challenge of disorganized email inboxes, where multiple categories of emails are mixed together. Users often have to go through each email individually, making it difficult to quickly identify their type or priority. By fine-tuning BERT variants for multi-label classification, we aim to automatically categorize emails into their respective classes, improving inbox organization and user efficiency.\n",
    "\n",
    "**Implementation Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Project Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import gc\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, hamming_loss\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the multi-label emails dataset\n",
    "dataset = load_dataset(\"imnim/multiclass-email-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: \n",
      " DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['subject', 'body', 'labels'],\n",
      "        num_rows: 2105\n",
      "    })\n",
      "})\n",
      "==================================================\n",
      "Dataset Shape: Rows-2105, Columns-3\n",
      "==================================================\n",
      "Sample Data: \n",
      " {'subject': 'Meeting Reminder: Quarterly Sales Review Tomorrow', 'body': 'Dear Team, Just a friendly reminder that our Quarterly Sales Review meeting is scheduled for tomorrow at 10:00 AM in the conference room. Please make sure to bring your sales reports and any relevant updates. Coffee and pastries will be provided. Looking forward to a productive meeting. Best regards, [Your Name]', 'labels': ['Business', 'Reminders']}\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset\n",
    "print(\"Dataset: \\n\", dataset)\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset Shape: Rows-{dataset['train'].num_rows}, Columns-{len(dataset['train'].column_names)}\")\n",
    "print(\"=\"*50)\n",
    "print(\"Sample Data: \\n\", dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine subject and body of each email into a single text field\n",
    "def combine_text(examples):\n",
    "    examples[\"text\"] = examples[\"subject\"] + \" \" + examples[\"body\"]\n",
    "    return examples\n",
    "\n",
    "\n",
    "# Apply the function to the dataset\n",
    "dataset = dataset.map(combine_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subject': 'Meeting Reminder: Quarterly Sales Review Tomorrow',\n",
       " 'body': 'Dear Team, Just a friendly reminder that our Quarterly Sales Review meeting is scheduled for tomorrow at 10:00 AM in the conference room. Please make sure to bring your sales reports and any relevant updates. Coffee and pastries will be provided. Looking forward to a productive meeting. Best regards, [Your Name]',\n",
       " 'labels': ['Business', 'Reminders'],\n",
       " 'text': 'Meeting Reminder: Quarterly Sales Review Tomorrow Dear Team, Just a friendly reminder that our Quarterly Sales Review meeting is scheduled for tomorrow at 10:00 AM in the conference room. Please make sure to bring your sales reports and any relevant updates. Coffee and pastries will be provided. Looking forward to a productive meeting. Best regards, [Your Name]'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the updated dataset\n",
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset before further processing\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "test_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode multi-labels using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(train_dataset[\"labels\"])\n",
    "num_labels = len(mlb.classes_)\n",
    "\n",
    "# Define a function to encode the labels\n",
    "def encode_labels(examples):\n",
    "    # Transform the entire list of labels for each sample\n",
    "    encoded = mlb.transform(examples[\"labels\"])\n",
    "    # Convert to float32 (important for multi-label)\n",
    "    examples[\"labels_encoded\"] = encoded.astype(np.float32).tolist()\n",
    "    return examples\n",
    "\n",
    "# Apply the function to the dataset\n",
    "train_dataset = train_dataset.map(encode_labels, batched=True)\n",
    "test_dataset = test_dataset.map(encode_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: [['Business', 'Reminders'], ['Promotions']]\n",
      "Encoded labels: [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]\n",
      "Label classes: ['Business' 'Customer Support' 'Events & Invitations' 'Finance & Bills'\n",
      " 'Job Application' 'Newsletters' 'Personal' 'Promotions' 'Reminders'\n",
      " 'Travel & Bookings']\n"
     ]
    }
   ],
   "source": [
    "# Check the encoded dataset\n",
    "print(\"Original labels:\", train_dataset[\"labels\"][:2])\n",
    "print(\"Encoded labels:\", train_dataset[\"labels_encoded\"][:2])\n",
    "print(\"Label classes:\", mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d2bf58998b47a7aea5c9478d73ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08c1c38da81427fad5e86e01c563519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt datasets successfully!\n",
      "Train columns: ['labels', 'labels_encoded', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize and encode from your original data\n",
    "def tokenize_and_encode(examples):\n",
    "    # Tokenize text\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        max_length=256,\n",
    "        padding=False,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    # Encode labels\n",
    "    encoded_labels = mlb.transform(examples[\"labels\"])\n",
    "    tokenized[\"labels\"] = encoded_labels.astype(np.float32).tolist()\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# Apply to clean datasets \n",
    "train_dataset = train_dataset.map(tokenize_and_encode, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_and_encode, batched=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns([\"subject\", \"body\", \"text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"subject\", \"body\", \"text\"])\n",
    "\n",
    "print(\"Rebuilt datasets successfully!\")\n",
    "print(\"Train columns:\", train_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample: {'labels': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'labels_encoded': [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], 'input_ids': [101, 14764, 1024, 9046, 2136, 3116, 6203, 2136, 2372, 1010, 2023, 2003, 1037, 5379, 14764, 2008, 2057, 2031, 2256, 4882, 2136, 3116, 5115, 2005, 4826, 2012, 2184, 1024, 4002, 2572, 1012, 3531, 2191, 2469, 2000, 3319, 1996, 11376, 25828, 1998, 2272, 4810, 2007, 2151, 14409, 2030, 20062, 2000, 3745, 1012, 2292, 1005, 1055, 2031, 1037, 13318, 3116, 1998, 6848, 2256, 5082, 2006, 7552, 3934, 1012, 2559, 2830, 2000, 3773, 2017, 2035, 2045, 999, 2190, 12362, 1010, 1031, 2115, 2171, 1033, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# Verify the structure\n",
    "print(\"Training sample:\", train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label: {0: 'Business', 1: 'Customer Support', 2: 'Events & Invitations', 3: 'Finance & Bills', 4: 'Job Application', 5: 'Newsletters', 6: 'Personal', 7: 'Promotions', 8: 'Reminders', 9: 'Travel & Bookings'}\n",
      "Label to ID: {'Business': 0, 'Customer Support': 1, 'Events & Invitations': 2, 'Finance & Bills': 3, 'Job Application': 4, 'Newsletters': 5, 'Personal': 6, 'Promotions': 7, 'Reminders': 8, 'Travel & Bookings': 9}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the label ids\n",
    "id2label = {i: label for i, label in enumerate(mlb.classes_)}\n",
    "label2id = {label: i for i, label in enumerate(mlb.classes_)}\n",
    "\n",
    "# Check the mappings\n",
    "print(\"ID to Label:\", id2label)\n",
    "print(\"Label to ID:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,           # Enable padding\n",
    "    return_tensors=\"pt\",    # Return PyTorch tensors\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-label-email-intent-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
